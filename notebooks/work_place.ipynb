{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ad15f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from torch.nn import BatchNorm1d, ReLU, Linear, Sequential\n",
    "import numpy as np\n",
    "from torch_geometric.data import Data, InMemoryDataset, download_url\n",
    "from torch_geometric.nn import GCNConv, global_mean_pool, GATConv, GINConv, global_add_pool\n",
    "import os\n",
    "from torch.utils.data import DataLoader\n",
    "import networkx as nx\n",
    "from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder\n",
    "from torch_geometric.transforms import NormalizeFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d2d58a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SuperPixDGL(torch.utils.data.Dataset):\n",
    "    def __init__(self,\n",
    "                 data_dir,\n",
    "                 dataset,\n",
    "                 split,\n",
    "                 graph_format='edge_wt_only_coord'):\n",
    "        assert graph_format in ['edge_wt_only_coord', 'edge_wt_coord_feat', 'edge_wt_region_boundary']\n",
    "        self.split = split\n",
    "        self.graph_lists = []\n",
    "\n",
    "        with open(os.path.join(data_dir, 'sample/COCO_500sp_%s_superpixels.pkl' % split), 'rb') as f:\n",
    "            self.superpixels = pickle.load(f)\n",
    "        \n",
    "        with open(os.path.join(data_dir, 'sample/COCO_500sp_%s.pkl' % split), 'rb') as f:\n",
    "            self.labels, self.sp_data = pickle.load(f)\n",
    "            self.sp_node_labels = self.labels\n",
    "        \n",
    "        if graph_format == 'edge_wt_region_boundary':\n",
    "            with open(os.path.join(data_dir, 'sample/COCO_500sp_%s_rag_boundary_graphs.pkl' % split), 'rb') as f:\n",
    "                self.region_boundary_graphs = pickle.load(f)\n",
    "\n",
    "        self.graph_format = graph_format \n",
    "        self.n_samples = len(self.labels)\n",
    "        \n",
    "        self._prepare()\n",
    "    \n",
    "    def _prepare(self):\n",
    "        print(\"preparing %d graphs for the %s set...\" % (self.n_samples, self.split.upper()))\n",
    "        self.Adj_matrices, self.node_features, self.edges_lists, self.edge_features = [], [], [], []\n",
    "        for index, sample in enumerate(self.sp_data):\n",
    "            mean_px, coord = sample[:2]\n",
    "            \n",
    "            try:\n",
    "                coord = coord / self.img_size\n",
    "            except AttributeError:\n",
    "                VOC_has_variable_image_sizes = True\n",
    "                \n",
    "            if self.graph_format == 'edge_wt_coord_feat':\n",
    "                A = compute_adjacency_matrix_images(coord, mean_px) # using super-pixel locations + features\n",
    "                edges_list, edge_values_list = compute_edges_list(A) \n",
    "            elif self.graph_format == 'edge_wt_only_coord':\n",
    "                A = compute_adjacency_matrix_images(coord, mean_px, False) # using only super-pixel locations\n",
    "                edges_list, edge_values_list = compute_edges_list(A) \n",
    "            elif self.graph_format == 'edge_wt_region_boundary':\n",
    "                A, edges_list, edge_values_list = None, None, None\n",
    "\n",
    "            N_nodes = mean_px.shape[0]\n",
    "            \n",
    "            mean_px = mean_px.reshape(N_nodes, -1)\n",
    "            coord = coord.reshape(N_nodes, 2)\n",
    "            x = np.concatenate((mean_px, coord), axis=1)\n",
    "\n",
    "            if edge_values_list is not None:\n",
    "                edge_values_list = edge_values_list.reshape(-1) \n",
    "            \n",
    "            self.node_features.append(x)\n",
    "            self.edge_features.append(edge_values_list) \n",
    "            self.Adj_matrices.append(A)\n",
    "            self.edges_lists.append(edges_list)\n",
    "        \n",
    "    def __len__(self):\n",
    "        \"\"\"Return the number of graphs in the dataset.\"\"\"\n",
    "        return self.n_samples\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        if self.graph_format == 'edge_wt_region_boundary':\n",
    "            if self.node_features[idx].shape[0] == 1:\n",
    "                # handling for 1 node where the self loop would be the only edge\n",
    "                # since, VOC Superpixels has few samples (5 samples) with only 1 node\n",
    "                g = dgl.DGLGraph()\n",
    "                g.add_nodes(self.node_features[idx].shape[0]) \n",
    "                g = dgl.add_self_loop(g)\n",
    "                # dummy edge feat since no actual edge present\n",
    "                g.edata['feat'] = torch.zeros(1, 2) # 1 edge and 2 feat dim\n",
    "                self.Adj_matrices[idx] = g.adjacency_matrix().to_dense().numpy()\n",
    "            else:\n",
    "                g = dgl.from_networkx(self.region_boundary_graphs[idx].to_directed(),\n",
    "                                  edge_attrs=['weight', 'count'])\n",
    "                g.edata['feat'] = torch.stack((g.edata['weight'], g.edata['count']),-1)\n",
    "                del g.edata['weight'], g.edata['count']\n",
    "                self.Adj_matrices[idx] = g.adjacency_matrix().to_dense().numpy()\n",
    "        else:\n",
    "            g = dgl.DGLGraph()\n",
    "            g.add_nodes(self.node_features[idx].shape[0])\n",
    "            for src, dsts in enumerate(self.edges_lists[idx]):\n",
    "                g.add_edges(src, dsts[dsts!=src])\n",
    "                \n",
    "        g.ndata['feat'] = torch.Tensor(self.node_features[idx])\n",
    "        \n",
    "        return g, self.sp_node_labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "82c120f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data, val_dict = torch.load(\"/home/zluo/nn/lrgb/datasets/peptides-functional/processed/geometric_data_processed.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c147e771",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(edge_index=[2, 4773974], edge_attr=[4773974, 3], x=[2344859, 9], y=[15535, 10])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "771872e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
